import torch
from torch.autograd import Variable
import torch.nn as nn
import torch.optim as optim

import matplotlib.pyplot as plt

# used to load and transform popular CV datasets
import torchvision
import torchvision.transforms as transforms 

from model import Generator, Discriminator

# to save and load numpy arrays
from os import fsync
import numpy as np
from numpy import save as np_save
from numpy import load as np_load

# import datasets
import sys
sys.path.append('../')
from Datasets.loadDataset import loadDataset, getHelperClass, getEpochs, getChannels
reload(sys.modules[loadDataset.__module__])

# to parse uint format
import os

import PIL.Image
from cStringIO import StringIO

# import configuration
import config
reload(config)
from config import *


%matplotlib inline

def sync(fh):
    """
    This makes sure data is written to disk, so that buffering doesn't influence the timings.
    """
    fh.flush()
    fsync(fh.fileno())
    
def test(dataSet, primaryClass, helperClass, primaryInstances, helperInstances):
    '''
    Inputs :
    
    dataSets : List : Datasets for which samples are to be genrated
    instances : List : Number of instances to be used from original dataset
    classes : List : Classes for which samples are to be generated
    
    Output :
    
    File with 1000 compressed images generated by GAN
    
    '''
    
    modelFolder = resultDir + 'models/MMDall'+'/'+dataSet+'/'+dataSet
    modelFile = modelFolder + '_' + str(primaryClass) + '_' + 'all' + '_' + \
                           str(primaryInstances) + '_' + str(helperInstances)+'_'+str(getEpochs(dataSet,primaryInstances)-1)+'.pt'
        

    
    
    print ('Generating examples for Dataset: '+dataSet+
           ' Primary Class: '+str(primaryClass)+
           ' Helper Class: '+str(helperClass)+
           ' Primary Instances: '+str(primaryInstances)+
           ' Helper Instances: '+str(helperInstances)+
           ' Epochs: '+str(getEpochs(dataSet,primaryInstances)))
    
    numOutputChannels = getChannels(dataSet)
    
    # load the model learnt during training
    G = Generator(numInputChannels, numGenFilter, numOutputChannels)
    G.load_state_dict(torch.load(modelFile))
    genImageConcat = np.empty(1)
    
    iterations = numOfSamples/batchSize
    
    for iteration in range(iterations):
        noise = torch.FloatTensor(batchSize,
                                  numInputChannels,
                                  1,
                                  1)
        noise.normal_(0,1)

        if cuda:
            G = G.cuda()
            noise = noise.cuda()
        noiseVariable = Variable(noise)

        genImage = G(noiseVariable)
        genImage = genImage.data
        genImage = genImage.cpu()
        genImage = genImage.numpy()
        
        
        if iteration==0:
            genImageConcat = genImage
        else:
            genImageConcat = np.concatenate((genImageConcat, genImage),
                                            axis=0)
            
        if iteration==(iterations-1):
            
            # normalize sets image pixels between 0 and 1
            genImage = torchvision.utils.make_grid(torch.from_numpy(genImage[:25]), nrow=5, normalize=True)
            
            # mapping between 0 to 1 as required by imshow,
            # otherwise the images are stored in the form -1 to 1
            # done through normalize=True
            
            genImage = genImage.permute(1,2,0)
            genImage = genImage.numpy()

            plt.imshow(genImage, cmap='gray')
            plotFileName = resultDir+'results'+'/'+'MMDall/samples'+'/'+dataSet+'/'+dataSet+ '_' + str(primaryClass) + '_' + str(helperClass) + '_' + str(primaryInstances) + '_' \
            + str(helperInstances)        
            plt.axis('off')

            plt.savefig(plotFileName, bbox_inches='tight')
            plt.show()
            

    path = resultDir+'results/MMDall'+'/'+'compressed'+'/'+dataSet+'/'+ dataSet + '_' \
            + str(primaryClass) + '_' + str(helperClass) + '_' + str(primaryInstances) + '_' \
            + str(helperInstances)  + '.npy'
        
    # save the image in some format
    with open(path,'wb+') as fh:
        genImageConcat = np.squeeze(genImageConcat)
        np_save(fh, genImageConcat, allow_pickle=False)
        sync(fh)  
        
def generateSamples(dataSets, classes, instances):
    '''
    Inputs :
    
    dataSets : List : Datasets for which samples are to be genrated
    instances : List : Number of instances to be used from original dataset
    classes : List : Classes for which samples are to be generated
    
    Outputs :
    
    .npy files with 1000 generated samples
    '''

    for dataSet in dataSets:
        for instance in instances:
            for cls in classes:
                # take it as GAN generated class
                test(dataSet, cls, instance)
                #showImageMatrix(dataSet, cls, instance,0)

if __name__=='__main__':
    

    from model_28 import Generator, Discriminator
    numGenFilter=64
    numDiscFilter=32
    imageSize = 28
    
    dataSet = ['MNIST','FashionMNIST']
    primaryClass = [0,1,2,3,4,5,6,7,8,9]
    primaryInstances = [100,500,1000,5000]
    helperInstances = [1000,5000]
    batchSizes = [50]
    
    for d in dataSet:
        for pc in primaryClass:
            for pi in primaryInstances:
                for hi in helperInstances:
                    if pi > hi:
                        continue
                    for b in batchSizes:
                        hc = getHelperClass(d,pc)
                        if hc==-1:
                            continue
                        test(d, pc, hc, pi, hi)        