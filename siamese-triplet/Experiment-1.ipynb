{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1 - Checking how a GAN performs when discriminator is converted to fully convolutional\n",
    "\n",
    "This is to check how the vanilla GAN framework performs in a 'DC-GAN' setting after the discriminator is changed from fully convolutional layers are changed to densely connected layers. First we will train a standard DCGAN. In the second experiment, we will change the discriminator tp be fully convolutional to look at the effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "# import activation functions\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# import optimization functions\n",
    "import torch.optim as optim\n",
    "\n",
    "# torch vision functions\n",
    "import torchvision\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from Datasets.loadDataset import loadDataset, getChannels\n",
    "reload(sys.modules[loadDataset.__module__])\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a standard dataset for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [i for i in range(10)]\n",
    "instances = [5000 for i in range(10)]\n",
    "batchSize = 128\n",
    "\n",
    "mnist_dataset = loadDataset('MNIST', classes, instances, 'train')\n",
    "mnist_dataloader = torch.utils.data.DataLoader(mnist_dataset, \n",
    "                                               batch_size = batchSize,\n",
    "                                               shuffle = True,\n",
    "                                               num_workers = 2,\n",
    "                                               drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "numInputChannels = 100\n",
    "numGenFilter = 32\n",
    "numDiscFilter = 32\n",
    "numOutputChannels = 1\n",
    "\n",
    "\n",
    "learningRate = 0.0002\n",
    "epochs = 100\n",
    "\n",
    "cuda = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showTrainHist(trainHist):\n",
    "    \n",
    "    '''\n",
    "    Plot Generator and Discriminator loss function\n",
    "    '''\n",
    "    x = range(len(trainHist['discLoss']))\n",
    "\n",
    "    y1 = trainHist['discLoss']\n",
    "    y2 = trainHist['genLoss']\n",
    "\n",
    "    plt.plot(x, y1, label='D_loss')\n",
    "    plt.plot(x, y2, label='G_loss')\n",
    "\n",
    "    plt.xlabel('Iter')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, train a fully convolutional generator and fully convolutional discriminator.\n",
    "\n",
    "<img src=\"./images/DCGAN.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainLoader,\n",
    "          learningRate = 0.0002,\n",
    "          epochs = 5):\n",
    "    \n",
    "    G = Generator(numInputChannels, numGenFilter, numOutputChannels)\n",
    "    D = Discriminator(numOutputChannels, numDiscFilter)\n",
    "    \n",
    "    #initialize the weights here\n",
    "    \n",
    "    # take the binary cross entropy loss \n",
    "    lossFunction = nn.BCELoss()\n",
    "    \n",
    "    genOptimizer = optim.Adam(G.parameters(),\n",
    "                              lr=learningRate,\n",
    "                              betas = (0.5,0.999))\n",
    "    discOptimizer = optim.Adam(D.parameters(),\n",
    "                               lr=learningRate,\n",
    "                               betas = (0.5,0.999))\n",
    "    \n",
    "    # real input to the discriminator\n",
    "    discRealInput = torch.FloatTensor(batchSize,\n",
    "                                      1,\n",
    "                                      32,\n",
    "                                      32)\n",
    "    discRealLabel = torch.FloatTensor(batchSize)\n",
    "    discRealLabel.fill_(1)\n",
    "    \n",
    "    discFakeInput = torch.FloatTensor(batchSize,\n",
    "                                      numInputChannels,\n",
    "                                      1,\n",
    "                                      1)\n",
    "    discFakeLabel = torch.FloatTensor(batchSize)\n",
    "    discFakeLabel.fill_(0)\n",
    "    \n",
    "    # to check the formation of image, we define a fixed noise vector\n",
    "    fixedNoise = torch.FloatTensor(batchSize,\n",
    "                                   numInputChannels,\n",
    "                                   1,\n",
    "                                   1)\n",
    "    fixedNoise.normal_(0,1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if cuda:\n",
    "        \n",
    "        G = G.cuda()\n",
    "        D = D.cuda()\n",
    "        \n",
    "        lossFunction = lossFunction.cuda()\n",
    "        \n",
    "        discRealInput = discRealInput.cuda()\n",
    "        discRealLabel = discRealLabel.cuda()\n",
    "        \n",
    "        discFakeInput = discFakeInput.cuda()\n",
    "        discFakeLabel = discFakeLabel.cuda()\n",
    "        \n",
    "        fixedNoise = fixedNoise.cuda()\n",
    "        \n",
    "    fixedNoiseV = Variable(fixedNoise)\n",
    "    \n",
    "    trainHist = {}\n",
    "    trainHist['discLoss'] = [] \n",
    "    trainHist['genLoss'] = []\n",
    "    trainHist['perEpochTime'] = []\n",
    "    trainHist['totalTime'] = []\n",
    "    \n",
    "        \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        generatorLosses = []\n",
    "        discriminatorLosses = []\n",
    "        \n",
    "        epochStartTime = time.time()\n",
    "        \n",
    "        \n",
    "        for i,data in enumerate(trainLoader, 0):\n",
    "            \n",
    "            # train discriminator D\n",
    "            \n",
    "            # set the gradients in computation graph of discriminator to be 0\n",
    "            D.zero_grad()\n",
    "            dataInstance, dataLabel = data\n",
    "            if cuda:\n",
    "                dataInstance = dataInstance.cuda()\n",
    "            \n",
    "            #print discRealInput.shape, dataInstance.shape\n",
    "            # train discriminator on real classes\n",
    "            discRealInput.copy_(dataInstance)\n",
    "            \n",
    "            discRealInputV = Variable(discRealInput)\n",
    "            discRealLabelV = Variable(discRealLabel)\n",
    "            \n",
    "            discRealOutput = D(discRealInputV)\n",
    "            \n",
    "            discLossReal = lossFunction(discRealOutput,\n",
    "                                        discRealLabelV)\n",
    "            \n",
    "            # calculate the gradients for nodes of computation graph\n",
    "            discLossReal.backward()\n",
    "            \n",
    "            # train discriminator on fake classes\n",
    "            discFakeInput.normal_(0,1)\n",
    "            discFakeInputV = Variable(discFakeInput)\n",
    "            discFakeLabelV = Variable(discFakeLabel)\n",
    "            \n",
    "            genFakeOutput = G(discFakeInputV)\n",
    "            \n",
    "            # detach the graph prior to D. So what weights in G do not get updated\n",
    "            discFakeOutput = D(genFakeOutput.detach())\n",
    "            \n",
    "            discLossFake = lossFunction(discFakeOutput,\n",
    "                                        discFakeLabelV)\n",
    "            \n",
    "            # calculate the gradients for nodes of computation graph\n",
    "            discLossFake.backward()\n",
    "            \n",
    "            # log the loss for discriminator\n",
    "            discriminatorLosses.append((discLossReal+discLossFake).data[0])\n",
    "            \n",
    "            # update the weights\n",
    "            discOptimizer.step()\n",
    "            \n",
    "            # train generator with discriminator feedback\n",
    "            G.zero_grad()\n",
    "            \n",
    "            discFakeOutput = D(genFakeOutput)\n",
    "            genLossFake = lossFunction(discFakeOutput, discRealLabelV)\n",
    "            \n",
    "            genLossFake.backward()\n",
    "            genOptimizer.step()\n",
    "            \n",
    "            # log the loss for generator\n",
    "            generatorLosses.append(genLossFake.data[0])\n",
    "                            \n",
    "        epochEndTime = time.time()\n",
    "        perEpochTime = epochEndTime - epochStartTime \n",
    "        discLoss = torch.mean(torch.FloatTensor(discriminatorLosses))\n",
    "        genLoss = torch.mean(torch.FloatTensor(generatorLosses))  \n",
    "        trainHist['discLoss'].append(discLoss)\n",
    "        trainHist['genLoss'].append(genLoss)\n",
    "        print ('Epoch : [%d/%d] time: %.2f, loss_d: %.3f, loss_g: %.3f'% (epoch+1,\n",
    "                                                                 epochs,\n",
    "                                                                 perEpochTime,\n",
    "                                                                 discLoss,\n",
    "                                                                 genLoss))\n",
    "        \n",
    "    # create an image for every epoch\n",
    "    # generate samples from trained generator\n",
    "    genImage = G(fixedNoiseV)\n",
    "    genImage = genImage.data\n",
    "    genImage = genImage.cpu()\n",
    "\n",
    "    genImage = torchvision.utils.make_grid(genImage, nrow=10)\n",
    "    genImage = (genImage/2) + 0.5\n",
    "    genImage = genImage.permute(1,2,0)\n",
    "    genImage = genImage.numpy()\n",
    "\n",
    "    plt.figure()\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    plt.imshow(genImage)\n",
    "    plt.axis('off')\n",
    "\n",
    "    txt = 'Epoch: '+ str(epoch+1)\n",
    "    fig.text(.45,.05,txt)\n",
    "    plt.show()\n",
    "    \n",
    "    showTrainHist(trainHist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1/100] time: 13.97, loss_d: 0.366, loss_g: 3.490\n",
      "Epoch : [2/100] time: 14.12, loss_d: 0.463, loss_g: 2.738\n",
      "Epoch : [3/100] time: 14.81, loss_d: 0.503, loss_g: 2.460\n",
      "Epoch : [4/100] time: 15.71, loss_d: 0.504, loss_g: 2.274\n",
      "Epoch : [5/100] time: 15.70, loss_d: 0.546, loss_g: 2.174\n",
      "Epoch : [6/100] time: 15.70, loss_d: 0.584, loss_g: 2.259\n",
      "Epoch : [7/100] time: 15.69, loss_d: 0.552, loss_g: 2.260\n",
      "Epoch : [8/100] time: 15.70, loss_d: 0.426, loss_g: 2.651\n",
      "Epoch : [9/100] time: 15.70, loss_d: 0.397, loss_g: 2.948\n",
      "Epoch : [10/100] time: 15.72, loss_d: 0.373, loss_g: 3.116\n",
      "Epoch : [11/100] time: 15.70, loss_d: 0.285, loss_g: 3.490\n",
      "Epoch : [12/100] time: 15.70, loss_d: 0.237, loss_g: 3.659\n",
      "Epoch : [13/100] time: 15.70, loss_d: 0.439, loss_g: 3.036\n",
      "Epoch : [14/100] time: 15.70, loss_d: 0.049, loss_g: 4.461\n",
      "Epoch : [15/100] time: 15.69, loss_d: 0.421, loss_g: 3.426\n",
      "Epoch : [16/100] time: 15.70, loss_d: 0.465, loss_g: 2.862\n",
      "Epoch : [17/100] time: 15.70, loss_d: 0.194, loss_g: 4.105\n",
      "Epoch : [18/100] time: 15.70, loss_d: 0.037, loss_g: 4.946\n",
      "Epoch : [19/100] time: 15.70, loss_d: 0.412, loss_g: 3.740\n",
      "Epoch : [20/100] time: 15.71, loss_d: 0.344, loss_g: 3.394\n",
      "Epoch : [21/100] time: 15.72, loss_d: 0.025, loss_g: 5.231\n",
      "Epoch : [22/100] time: 15.72, loss_d: 0.445, loss_g: 3.630\n",
      "Epoch : [23/100] time: 15.71, loss_d: 0.023, loss_g: 5.310\n",
      "Epoch : [24/100] time: 15.70, loss_d: 0.638, loss_g: 2.682\n",
      "Epoch : [25/100] time: 15.72, loss_d: 0.042, loss_g: 4.835\n",
      "Epoch : [26/100] time: 15.69, loss_d: 0.147, loss_g: 4.727\n",
      "Epoch : [27/100] time: 15.71, loss_d: 0.436, loss_g: 3.604\n",
      "Epoch : [28/100] time: 15.70, loss_d: 0.246, loss_g: 4.548\n",
      "Epoch : [29/100] time: 15.70, loss_d: 0.491, loss_g: 2.717\n",
      "Epoch : [30/100] time: 15.70, loss_d: 0.034, loss_g: 5.003\n",
      "Epoch : [31/100] time: 15.70, loss_d: 0.015, loss_g: 5.756\n",
      "Epoch : [32/100] time: 15.71, loss_d: 0.215, loss_g: 5.020\n",
      "Epoch : [33/100] time: 15.70, loss_d: 0.368, loss_g: 3.332\n",
      "Epoch : [34/100] time: 15.71, loss_d: 0.049, loss_g: 4.746\n",
      "Epoch : [35/100] time: 15.70, loss_d: 0.009, loss_g: 6.340\n",
      "Epoch : [36/100] time: 15.72, loss_d: 0.471, loss_g: 4.169\n",
      "Epoch : [37/100] time: 15.71, loss_d: 0.284, loss_g: 3.947\n",
      "Epoch : [38/100] time: 15.70, loss_d: 0.386, loss_g: 3.344\n",
      "Epoch : [39/100] time: 15.70, loss_d: 0.018, loss_g: 5.752\n",
      "Epoch : [40/100] time: 15.70, loss_d: 0.236, loss_g: 4.808\n",
      "Epoch : [41/100] time: 15.70, loss_d: 0.440, loss_g: 3.314\n",
      "Epoch : [42/100] time: 15.72, loss_d: 0.044, loss_g: 4.967\n",
      "Epoch : [43/100] time: 15.72, loss_d: 0.010, loss_g: 6.220\n",
      "Epoch : [44/100] time: 15.70, loss_d: 0.008, loss_g: 6.527\n",
      "Epoch : [45/100] time: 15.70, loss_d: 0.483, loss_g: 3.580\n",
      "Epoch : [46/100] time: 15.70, loss_d: 0.328, loss_g: 3.408\n",
      "Epoch : [47/100] time: 15.70, loss_d: 0.332, loss_g: 3.819\n",
      "Epoch : [48/100] time: 15.71, loss_d: 0.025, loss_g: 5.551\n",
      "Epoch : [49/100] time: 15.69, loss_d: 0.009, loss_g: 6.429\n",
      "Epoch : [50/100] time: 15.70, loss_d: 0.371, loss_g: 4.065\n",
      "Epoch : [51/100] time: 15.70, loss_d: 0.369, loss_g: 3.287\n",
      "Epoch : [52/100] time: 15.70, loss_d: 0.136, loss_g: 4.488\n",
      "Epoch : [53/100] time: 15.70, loss_d: 0.013, loss_g: 5.983\n",
      "Epoch : [54/100] time: 15.70, loss_d: 0.167, loss_g: 5.133\n",
      "Epoch : [55/100] time: 15.70, loss_d: 0.389, loss_g: 3.938\n",
      "Epoch : [56/100] time: 15.71, loss_d: 0.110, loss_g: 4.808\n",
      "Epoch : [57/100] time: 15.70, loss_d: 0.367, loss_g: 3.475\n",
      "Epoch : [58/100] time: 15.69, loss_d: 0.016, loss_g: 5.850\n",
      "Epoch : [59/100] time: 15.71, loss_d: 0.009, loss_g: 6.430\n",
      "Epoch : [60/100] time: 15.70, loss_d: 0.341, loss_g: 5.722\n",
      "Epoch : [61/100] time: 15.70, loss_d: 0.496, loss_g: 2.731\n",
      "Epoch : [62/100] time: 15.72, loss_d: 0.274, loss_g: 3.507\n",
      "Epoch : [63/100] time: 15.71, loss_d: 0.141, loss_g: 4.545\n",
      "Epoch : [64/100] time: 15.70, loss_d: 0.327, loss_g: 4.581\n",
      "Epoch : [65/100] time: 15.70, loss_d: 0.314, loss_g: 3.487\n",
      "Epoch : [66/100] time: 15.69, loss_d: 0.138, loss_g: 4.497\n",
      "Epoch : [67/100] time: 15.70, loss_d: 0.094, loss_g: 5.926\n",
      "Epoch : [68/100] time: 15.69, loss_d: 0.054, loss_g: 5.366\n",
      "Epoch : [69/100] time: 15.70, loss_d: 0.377, loss_g: 3.849\n",
      "Epoch : [70/100] time: 15.70, loss_d: 0.165, loss_g: 4.419\n",
      "Epoch : [71/100] time: 15.70, loss_d: 0.183, loss_g: 4.508\n",
      "Epoch : [72/100] time: 15.70, loss_d: 0.014, loss_g: 5.995\n",
      "Epoch : [73/100] time: 15.70, loss_d: 0.007, loss_g: 6.783\n",
      "Epoch : [74/100] time: 15.72, loss_d: 0.196, loss_g: 6.343\n",
      "Epoch : [75/100] time: 15.70, loss_d: 0.390, loss_g: 3.100\n",
      "Epoch : [76/100] time: 15.72, loss_d: 0.386, loss_g: 3.324\n",
      "Epoch : [77/100] time: 15.71, loss_d: 0.152, loss_g: 4.194\n",
      "Epoch : [78/100] time: 15.71, loss_d: 0.013, loss_g: 6.107\n",
      "Epoch : [79/100] time: 15.72, loss_d: 0.008, loss_g: 6.718\n",
      "Epoch : [80/100] time: 15.71, loss_d: 0.249, loss_g: 4.236\n",
      "Epoch : [81/100] time: 15.70, loss_d: 0.456, loss_g: 3.316\n",
      "Epoch : [82/100] time: 15.70, loss_d: 0.057, loss_g: 4.810\n",
      "Epoch : [83/100] time: 15.71, loss_d: 0.015, loss_g: 6.124\n",
      "Epoch : [84/100] time: 15.71, loss_d: 0.364, loss_g: 3.643\n",
      "Epoch : [85/100] time: 15.70, loss_d: 0.294, loss_g: 3.821\n",
      "Epoch : [86/100] time: 15.70, loss_d: 0.091, loss_g: 4.528\n",
      "Epoch : [87/100] time: 15.71, loss_d: 0.011, loss_g: 6.398\n",
      "Epoch : [88/100] time: 15.70, loss_d: 0.357, loss_g: 4.840\n",
      "Epoch : [89/100] time: 15.69, loss_d: 0.280, loss_g: 3.719\n",
      "Epoch : [90/100] time: 15.70, loss_d: 0.018, loss_g: 6.168\n",
      "Epoch : [91/100] time: 15.70, loss_d: 0.007, loss_g: 6.912\n",
      "Epoch : [92/100] time: 15.70, loss_d: 0.326, loss_g: 5.091\n",
      "Epoch : [93/100] time: 15.71, loss_d: 0.313, loss_g: 3.607\n",
      "Epoch : [94/100] time: 15.71, loss_d: 0.141, loss_g: 4.934\n",
      "Epoch : [95/100] time: 15.70, loss_d: 0.221, loss_g: 4.160\n",
      "Epoch : [96/100] time: 15.70, loss_d: 0.097, loss_g: 5.025\n"
     ]
    }
   ],
   "source": [
    "from model import Generator, Discriminator\n",
    "\n",
    "train(mnist_dataloader, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, train a fully convolutional generator and densley connected discriminator.\n",
    "\n",
    "<img src=\"./images/GAN_disc.png\"  >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_alt import Generator, Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainLoader,\n",
    "          learningRate = 0.0002,\n",
    "          epochs = 5):\n",
    "    \n",
    "    G = Generator(numInputChannels, numGenFilter, numOutputChannels)\n",
    "    D = Discriminator(1)\n",
    "    # take the binary cross entropy loss \n",
    "    lossFunction = nn.BCELoss()\n",
    "    \n",
    "    genOptimizer = optim.Adam(G.parameters(),\n",
    "                              lr=learningRate,\n",
    "                              betas = (0.5,0.999))\n",
    "    discOptimizer = optim.Adam(D.parameters(),\n",
    "                               lr=learningRate,\n",
    "                               betas = (0.5,0.999))\n",
    "    \n",
    "    # real input to the discriminator\n",
    "    discRealInput = torch.FloatTensor(batchSize,\n",
    "                                      1,\n",
    "                                      32,\n",
    "                                      32)\n",
    "    discRealLabel = torch.FloatTensor(batchSize)\n",
    "    discRealLabel.fill_(1)\n",
    "    \n",
    "    discFakeInput = torch.FloatTensor(batchSize,\n",
    "                                      numInputChannels,\n",
    "                                      1,\n",
    "                                      1)\n",
    "    discFakeLabel = torch.FloatTensor(batchSize)\n",
    "    discFakeLabel.fill_(0)\n",
    "    \n",
    "    # to check the formation of image, we define a fixed noise vector\n",
    "    fixedNoise = torch.FloatTensor(batchSize,\n",
    "                                   numInputChannels,\n",
    "                                   1,\n",
    "                                   1)\n",
    "    fixedNoise.normal_(0,1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if cuda:\n",
    "        \n",
    "        G = G.cuda()\n",
    "        D = D.cuda()\n",
    "        \n",
    "        lossFunction = lossFunction.cuda()\n",
    "        \n",
    "        discRealInput = discRealInput.cuda()\n",
    "        discRealLabel = discRealLabel.cuda()\n",
    "        \n",
    "        discFakeInput = discFakeInput.cuda()\n",
    "        discFakeLabel = discFakeLabel.cuda()\n",
    "        \n",
    "        fixedNoise = fixedNoise.cuda()\n",
    "        \n",
    "    fixedNoiseV = Variable(fixedNoise)\n",
    "    \n",
    "    trainHist = {}\n",
    "    trainHist['discLoss'] = [] \n",
    "    trainHist['genLoss'] = []\n",
    "    trainHist['perEpochTime'] = []\n",
    "    trainHist['totalTime'] = []\n",
    "    \n",
    "        \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        generatorLosses = []\n",
    "        discriminatorLosses = []\n",
    "        \n",
    "        epochStartTime = time.time()\n",
    "        \n",
    "        \n",
    "        for i,data in enumerate(trainLoader, 0):\n",
    "            \n",
    "            # train discriminator D\n",
    "            \n",
    "            # set the gradients in computation graph of discriminator to be 0\n",
    "            D.zero_grad()\n",
    "            dataInstance, dataLabel = data\n",
    "            if cuda:\n",
    "                dataInstance = dataInstance.cuda()\n",
    "            \n",
    "            #print discRealInput.shape, dataInstance.shape\n",
    "            # train discriminator on real classes\n",
    "            discRealInput.copy_(dataInstance)\n",
    "            \n",
    "            discRealInputV = Variable(discRealInput)\n",
    "            discRealLabelV = Variable(discRealLabel)\n",
    "            \n",
    "            discRealOutput = D(discRealInputV.view(batchSize,-1))\n",
    "            \n",
    "            discLossReal = lossFunction(discRealOutput,\n",
    "                                        discRealLabelV)\n",
    "            \n",
    "            # calculate the gradients for nodes of computation graph\n",
    "            discLossReal.backward()\n",
    "            \n",
    "            # train discriminator on fake classes\n",
    "            discFakeInput.normal_(0,1)\n",
    "            discFakeInputV = Variable(discFakeInput)\n",
    "            discFakeLabelV = Variable(discFakeLabel)\n",
    "            \n",
    "            genFakeOutput = G(discFakeInputV)\n",
    "            genFakeOutput = genFakeOutput.view(batchSize,-1)\n",
    "            \n",
    "            # detach the graph prior to D. So what weights in G do not get updated\n",
    "            discFakeOutput = D(genFakeOutput.detach())\n",
    "            \n",
    "            discLossFake = lossFunction(discFakeOutput,\n",
    "                                        discFakeLabelV)\n",
    "            \n",
    "            # calculate the gradients for nodes of computation graph\n",
    "            discLossFake.backward()\n",
    "            \n",
    "            # log the loss for discriminator\n",
    "            discriminatorLosses.append((discLossReal+discLossFake).data[0])\n",
    "            \n",
    "            # update the weights\n",
    "            discOptimizer.step()\n",
    "            \n",
    "            # train generator with discriminator feedback\n",
    "            G.zero_grad()\n",
    "            \n",
    "            discFakeOutput = D(genFakeOutput)\n",
    "            genLossFake = lossFunction(discFakeOutput, discRealLabelV)\n",
    "            \n",
    "            genLossFake.backward()\n",
    "            genOptimizer.step()\n",
    "            \n",
    "            # log the loss for generator\n",
    "            generatorLosses.append(genLossFake.data[0])\n",
    "                            \n",
    "        epochEndTime = time.time()\n",
    "        perEpochTime = epochEndTime - epochStartTime \n",
    "        discLoss = torch.mean(torch.FloatTensor(discriminatorLosses))\n",
    "        genLoss = torch.mean(torch.FloatTensor(generatorLosses))  \n",
    "        trainHist['discLoss'].append(discLoss)\n",
    "        trainHist['genLoss'].append(genLoss)\n",
    "        print ('Epoch : [%d/%d] time: %.2f, loss_d: %.3f, loss_g: %.3f'% (epoch+1,\n",
    "                                                                 epochs,\n",
    "                                                                 perEpochTime,\n",
    "                                                                 discLoss,\n",
    "                                                                 genLoss))\n",
    "        \n",
    "    # create an image for every epoch\n",
    "    # generate samples from trained generator\n",
    "    genImage = G(fixedNoiseV)\n",
    "    genImage = genImage.data\n",
    "    genImage = genImage.cpu()\n",
    "\n",
    "    genImage = torchvision.utils.make_grid(genImage, nrow=10)\n",
    "    genImage = (genImage/2) + 0.5\n",
    "    genImage = genImage.permute(1,2,0)\n",
    "    genImage = genImage.numpy()\n",
    "\n",
    "    plt.figure()\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    plt.imshow(genImage)\n",
    "    plt.axis('off')\n",
    "\n",
    "    txt = 'Epoch: '+ str(epoch+1)\n",
    "    fig.text(.45,.05,txt)\n",
    "    plt.show()\n",
    "    \n",
    "    showTrainHist(trainHist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(mnist_dataloader, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, train aconditional GAN with fully convolutional generator and fully convolutional discriminator.\n",
    "\n",
    "<img src=\"./images/cDCGAN.png\"  >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_C import Generator, Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainLoader,\n",
    "          learningRate = 0.0002,\n",
    "          epochs = 5):\n",
    "    \n",
    "    G = Generator(numInputChannels, numGenFilter, numOutputChannels)\n",
    "    D = Discriminator(numOutputChannels, numDiscFilter)\n",
    "    # take the binary cross entropy loss \n",
    "    lossFunction = nn.BCELoss()\n",
    "    \n",
    "    genOptimizer = optim.Adam(G.parameters(),\n",
    "                              lr=learningRate,\n",
    "                              betas = (0.5,0.999))\n",
    "    discOptimizer = optim.Adam(D.parameters(),\n",
    "                               lr=learningRate,\n",
    "                               betas = (0.5,0.999))\n",
    "    \n",
    "    # real input to the discriminator\n",
    "    discRealInput = torch.FloatTensor(batchSize,\n",
    "                                      1,\n",
    "                                      32,\n",
    "                                      32)\n",
    "    discRealLabel = torch.FloatTensor(batchSize)\n",
    "    discRealLabel.fill_(1)\n",
    "    \n",
    "    discFakeInput = torch.FloatTensor(batchSize,\n",
    "                                      numInputChannels,\n",
    "                                      1,\n",
    "                                      1)\n",
    "    discFakeLabel = torch.FloatTensor(batchSize)\n",
    "    discFakeLabel.fill_(0)\n",
    "    \n",
    "    # to check the formation of image, we define a fixed noise vector\n",
    "    fixedNoise = torch.FloatTensor(batchSize,\n",
    "                                   numInputChannels,\n",
    "                                   1,\n",
    "                                   1)\n",
    "    fixedNoise.normal_(0,1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if cuda:\n",
    "        \n",
    "        G = G.cuda()\n",
    "        D = D.cuda()\n",
    "        \n",
    "        lossFunction = lossFunction.cuda()\n",
    "        \n",
    "        discRealInput = discRealInput.cuda()\n",
    "        discRealLabel = discRealLabel.cuda()\n",
    "        \n",
    "        discFakeInput = discFakeInput.cuda()\n",
    "        discFakeLabel = discFakeLabel.cuda()\n",
    "        \n",
    "        fixedNoise = fixedNoise.cuda()\n",
    "        \n",
    "    fixedNoiseV = Variable(fixedNoise)\n",
    "    \n",
    "    trainHist = {}\n",
    "    trainHist['discLoss'] = [] \n",
    "    trainHist['genLoss'] = []\n",
    "    trainHist['perEpochTime'] = []\n",
    "    trainHist['totalTime'] = []\n",
    "    \n",
    "        \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        generatorLosses = []\n",
    "        discriminatorLosses = []\n",
    "        \n",
    "        epochStartTime = time.time()\n",
    "        \n",
    "        \n",
    "        for i,data in enumerate(trainLoader, 0):\n",
    "            \n",
    "            # train discriminator D\n",
    "            \n",
    "            # set the gradients in computation graph of discriminator to be 0\n",
    "            D.zero_grad()\n",
    "            dataInstance, dataLabel = data\n",
    "            if cuda:\n",
    "                dataInstance = dataInstance.cuda()\n",
    "            \n",
    "            #print discRealInput.shape, dataInstance.shape\n",
    "            # train discriminator on real classes\n",
    "            discRealInput.copy_(dataInstance)\n",
    "            \n",
    "            discRealInputV = Variable(discRealInput)\n",
    "            discRealLabelV = Variable(discRealLabel)\n",
    "            \n",
    "            discRealOutput = D(discRealInputV)\n",
    "            \n",
    "            discLossReal = lossFunction(discRealOutput,\n",
    "                                        discRealLabelV)\n",
    "            \n",
    "            # calculate the gradients for nodes of computation graph\n",
    "            discLossReal.backward()\n",
    "            \n",
    "            # train discriminator on fake classes\n",
    "            discFakeInput.normal_(0,1)\n",
    "            discFakeInputV = Variable(discFakeInput)\n",
    "            discFakeLabelV = Variable(discFakeLabel)\n",
    "            \n",
    "            genFakeOutput = G(discFakeInputV)\n",
    "            \n",
    "            # detach the graph prior to D. So what weights in G do not get updated\n",
    "            discFakeOutput = D(genFakeOutput.detach())\n",
    "            \n",
    "            discLossFake = lossFunction(discFakeOutput,\n",
    "                                        discFakeLabelV)\n",
    "            \n",
    "            # calculate the gradients for nodes of computation graph\n",
    "            discLossFake.backward()\n",
    "            \n",
    "            # log the loss for discriminator\n",
    "            discriminatorLosses.append((discLossReal+discLossFake).data[0])\n",
    "            \n",
    "            # update the weights\n",
    "            discOptimizer.step()\n",
    "            \n",
    "            # train generator with discriminator feedback\n",
    "            G.zero_grad()\n",
    "            \n",
    "            discFakeOutput = D(genFakeOutput)\n",
    "            genLossFake = lossFunction(discFakeOutput, discRealLabelV)\n",
    "            \n",
    "            genLossFake.backward()\n",
    "            genOptimizer.step()\n",
    "            \n",
    "            # log the loss for generator\n",
    "            generatorLosses.append(genLossFake.data[0])\n",
    "                            \n",
    "        epochEndTime = time.time()\n",
    "        perEpochTime = epochEndTime - epochStartTime \n",
    "        discLoss = torch.mean(torch.FloatTensor(discriminatorLosses))\n",
    "        genLoss = torch.mean(torch.FloatTensor(generatorLosses))  \n",
    "        trainHist['discLoss'].append(discLoss)\n",
    "        trainHist['genLoss'].append(genLoss)\n",
    "        print ('Epoch : [%d/%d] time: %.2f, loss_d: %.3f, loss_g: %.3f'% (epoch+1,\n",
    "                                                                 epochs,\n",
    "                                                                 perEpochTime,\n",
    "                                                                 discLoss,\n",
    "                                                                 genLoss))\n",
    "        \n",
    "    # create an image for every epoch\n",
    "    # generate samples from trained generator\n",
    "    genImage = G(fixedNoiseV)\n",
    "    genImage = genImage.data\n",
    "    genImage = genImage.cpu()\n",
    "\n",
    "    genImage = torchvision.utils.make_grid(genImage, nrow=10)\n",
    "    genImage = (genImage/2) + 0.5\n",
    "    genImage = genImage.permute(1,2,0)\n",
    "    genImage = genImage.numpy()\n",
    "\n",
    "    plt.figure()\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    plt.imshow(genImage)\n",
    "    plt.axis('off')\n",
    "\n",
    "    txt = 'Epoch: '+ str(epoch+1)\n",
    "    fig.text(.45,.05,txt)\n",
    "    plt.show()\n",
    "    \n",
    "    showTrainHist(trainHist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, train aconditional GAN with fully convolutional generator and densely connected discriminator.\n",
    "\n",
    "<img src=\"./images/cGAN_disc.png\"  >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1024])\n"
     ]
    }
   ],
   "source": [
    "x=torch.FloatTensor(np.random.randn(128,1,32,32))\n",
    "y=Variable(x)\n",
    "bs, c, w, h = y.data.shape\n",
    "y = y.view(bs,-1)\n",
    "print y.data.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
